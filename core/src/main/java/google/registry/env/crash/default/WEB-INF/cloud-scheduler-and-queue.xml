<?xml version="1.0" encoding="UTF-8"?>
<entries>
  <!-- Cloud Scheduler begin -->
  <!--
    /cron/fanout params:
        queue=<QUEUE_NAME>
        endpoint=<ENDPOINT_NAME> // URL Path of servlet, which may contain placeholders:
        runInEmpty               // Run once, with no tld parameter
        forEachRealTld           // Run for tlds with getTldType() == TldType.REAL
        forEachTestTld           // Run for tlds with getTldType() == TldType.TEST
        exclude=TLD1[,TLD2]      // exclude something otherwise included
   -->

  <task>
    <url>/_dr/task/rdeStaging</url>
    <name>rdeStaging</name>
    <description>
      This job generates a full RDE escrow deposit as a single gigantic XML document
      and streams it to cloud storage. When this job has finished successfully, it'll
      launch a separate task that uploads the deposit file to Iron Mountain via SFTP.
    </description>
    <!--
      This only needs to run once per day, but we launch additional jobs in case the
      cursor is lagging behind, so it'll catch up to the current date as quickly as
      possible. The only job that'll run under normal circumstances is the one that's
      close to midnight, since if the cursor is up-to-date, the task is a no-op.
      We want it to be close to midnight because that reduces the chance that the
      point-in-time code won't have to go to the extra trouble of fetching old
      versions of objects from the database. However, we don't want it to run too
      close to midnight, because there's always a chance that a change which was
      timestamped before midnight hasn't fully been committed to the database. So
      we add a 4+ minute grace period to ensure the transactions cool down, since
      our queries are not transactional.
    -->
    <schedule>7 */4 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=rde-upload&endpoint=/_dr/task/rdeUpload&forEachRealTld]]></url>
    <name>rdeUpload</name>
    <description>
      This job is a no-op unless RdeUploadCursor falls behind for some reason.
    </description>
    <schedule>0 */4 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=rde-report&endpoint=/_dr/task/rdeReport&forEachRealTld]]></url>
    <name>rdeReport</name>
    <description>
      This job is a no-op unless RdeReportCursor falls behind for some reason.
    </description>
    <schedule>0 */4 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=marksdb&endpoint=/_dr/task/tmchDnl&runInEmpty]]></url>
    <name>tmchDnl</name>
    <description>
      This job downloads the latest DNL from MarksDB and inserts it into the database.
      (See: TmchDnlAction, ClaimsList)
    </description>
    <schedule>0 */12 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=marksdb&endpoint=/_dr/task/tmchSmdrl&runInEmpty]]></url>
    <name>tmchSmdrl</name>
    <description>
      This job downloads the latest SMDRL from MarksDB and inserts it into the database.
      (See: TmchSmdrlAction, SignedMarkRevocationList)
    </description>
    <schedule>15 */12 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=marksdb&endpoint=/_dr/task/tmchCrl&runInEmpty]]></url>
    <name>tmchCrl</name>
    <description>
      This job downloads the latest CRL from MarksDB and inserts it into the database.
      (See: TmchCrlAction)
    </description>
    <schedule>0 */12 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=retryable-cron-tasks&endpoint=/_dr/task/syncGroupMembers&runInEmpty]]></url>
    <name>syncGroupMembers</name>
    <description>
      Syncs RegistrarContact changes in the past hour to Google Groups.
    </description>
    <schedule>0 */1 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=sheet&endpoint=/_dr/task/syncRegistrarsSheet&runInEmpty]]></url>
    <name>syncRegistrarsSheet</name>
    <description>
      Synchronize Registrar entities to Google Spreadsheets.
    </description>
    <schedule>0 */1 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=retryable-cron-tasks&endpoint=/_dr/task/deleteProberData&runInEmpty]]></url>
    <name>deleteProberData</name>
    <description>
      This job clears out data from probers and runs once a week.
    </description>
    <schedule>0 14 * * 1</schedule>
  </task>

  <!-- TODO: Add borgmon job to check that these files are created and updated successfully. -->
  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=retryable-cron-tasks&endpoint=/_dr/task/exportReservedTerms&forEachRealTld]]></url>
    <name>exportReservedTerms</name>
    <description>
      Reserved terms export to Google Drive job for creating once-daily exports.
    </description>
    <schedule>30 5 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=retryable-cron-tasks&endpoint=/_dr/task/exportPremiumTerms&forEachRealTld]]></url>
    <name>exportPremiumTerms</name>
    <description>
      Exports premium price lists to the Google Drive folders for each TLD once per day.
    </description>
    <schedule>0 5 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/readDnsQueue?jitterSeconds=45]]></url>
    <name>readDnsQueue</name>
    <description>
      Lease all tasks from the dns-pull queue, group by TLD, and invoke PublishDnsUpdates for each
      group.
    </description>
    <schedule>*/1 * * * *</schedule>
  </task>

  <task>
    <url>
      <![CDATA[/_dr/cron/fanout?queue=dns-refresh&forEachRealTld&forEachTestTld&endpoint=/_dr/task/readDnsRefreshRequests&dnsJitterSeconds=45]]></url>
    <name>readDnsRefreshRequests</name>
    <description>
      Enqueue a ReadDnsRefreshRequestAction for each TLD.
    </description>
    <schedule>*/1 * * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/task/deleteExpiredDomains]]></url>
    <name>deleteExpiredDomains</name>
    <description>
      This job runs an action that deletes domains that are past their
      autorenew end date.
    </description>
    <schedule>7 3 * * *</schedule>
  </task>

  <!--
    The next two wipeout jobs are required when crash has production data.
   -->
  <task>
    <url><![CDATA[/_dr/task/wipeOutCloudSql]]></url>
    <name>wipeOutCloudSql</name>
    <description>
      This job runs an action that deletes all data in Cloud SQL.
    </description>
    <schedule>7 3 * * 6</schedule>
  </task>
  <!-- Cloud Scheduler end -->

  <!-- Queue template with all supported params -->
  <!-- More information - https://cloud.google.com/sdk/gcloud/reference/tasks/queues/create -->
  <!--
    <queue>
      <name></name>
      <max-attempts></max-attempts>
      <max-backoff></max-backoff>
      <max-concurrent-dispatches></max-concurrent-dispatches>
      <max-dispatches-per-second></max-dispatches-per-second>
      <max-doublings></max-doublings>
      <max-retry-duration></max-retry-duration>
      <min-backoff></min-backoff>
      <routing-override></routing-override>
    </queue>
  -->

  <!-- Queue for reading DNS update requests and batching them off to the dns-publish queue. -->
  <queue>
    <name>dns-refresh</name>
    <max-dispatches-per-second>100</max-dispatches-per-second>
  </queue>

  <!-- Queue for publishing DNS updates in batches. -->
  <queue>
    <name>dns-publish</name>
    <max-dispatches-per-second>100</max-dispatches-per-second>
    <!-- 30 sec backoff increasing linearly up to 30 minutes. -->
    <min-backoff>30s</min-backoff>
    <max-backoff>1800s</max-backoff>
    <max-doublings>0</max-doublings>
  </queue>

  <!-- Queue for uploading RDE deposits to the escrow provider. -->
  <queue>
    <name>rde-upload</name>
    <max-dispatches-per-second>0.166666667</max-dispatches-per-second>
    <max-concurrent-dispatches>5</max-concurrent-dispatches>
    <max-retry-duration>14400s</max-retry-duration>
  </queue>

  <!-- Queue for uploading RDE reports to ICANN. -->
  <queue>
    <name>rde-report</name>
    <max-dispatches-per-second>1</max-dispatches-per-second>
    <max-concurrent-dispatches>1</max-concurrent-dispatches>
    <max-retry-duration>14400s</max-retry-duration>
  </queue>

  <!-- Queue for copying BRDA deposits to GCS. -->
  <queue>
    <name>brda</name>
    <max-dispatches-per-second>0.016666667</max-dispatches-per-second>
    <max-concurrent-dispatches>10</max-concurrent-dispatches>
    <max-retry-duration>82800s</max-retry-duration>
  </queue>

  <!-- Queue for tasks that trigger domain DNS update upon host rename. -->
  <queue>
    <name>async-host-rename</name>
    <max-dispatches-per-second>1</max-dispatches-per-second>
  </queue>

  <!-- Queue for tasks that wait for a Beam pipeline to complete (i.e. Spec11 and invoicing). -->
  <queue>
    <name>beam-reporting</name>
    <max-dispatches-per-second>0.016666667</max-dispatches-per-second>
    <max-concurrent-dispatches>1</max-concurrent-dispatches>
    <max-attempts>5</max-attempts>
    <min-backoff>180s</min-backoff>
    <max-backoff>180s</max-backoff>
  </queue>


  <!-- Queue for tasks that communicate with TMCH MarksDB webserver. -->
  <queue>
    <name>marksdb</name>
    <max-dispatches-per-second>0.016666667</max-dispatches-per-second>
    <max-concurrent-dispatches>1</max-concurrent-dispatches>
    <max-retry-duration>39600s</max-retry-duration>  <!-- cron interval minus hour -->
  </queue>

  <!-- Queue for tasks to produce LORDN CSV reports, populated by a Cloud Scheduler fanout job. -->
  <queue>
    <name>nordn</name>
    <max-dispatches-per-second>1</max-dispatches-per-second>
    <max-concurrent-dispatches>10</max-concurrent-dispatches>
    <max-retry-duration>39600s</max-retry-duration>  <!-- cron interval minus hour -->
  </queue>

  <!-- Queue for tasks that sync data to Google Spreadsheets. -->
  <queue>
    <name>sheet</name>
    <max-dispatches-per-second>1</max-dispatches-per-second>
    <!-- max-concurrent-requests is intentionally omitted. -->
    <max-retry-duration>3600s</max-retry-duration>
  </queue>

  <!-- Queue for infrequent cron tasks (i.e. hourly or less often) that should retry three times on failure. -->
  <queue>
    <name>retryable-cron-tasks</name>
    <max-dispatches-per-second>1</max-dispatches-per-second>
    <max-attempts>3</max-attempts>
  </queue>

  <!--  &lt;!&ndash; Queue for async actions that should be run at some point in the future. &ndash;&gt;-->
  <queue>
    <name>async-actions</name>
    <max-dispatches-per-second>1</max-dispatches-per-second>
    <max-concurrent-dispatches>5</max-concurrent-dispatches>
  </queue>

</entries>
