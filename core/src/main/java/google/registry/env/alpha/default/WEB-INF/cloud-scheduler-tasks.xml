<?xml version="1.0" encoding="UTF-8"?>
<cronentries>
  <cron>
    <url>/_dr/task/rdeStaging</url>
    <name>rdeStaging</name>
    <method>GET</method>
    <description>
      This job generates a full RDE escrow deposit as a single gigantic XML document
      and streams it to cloud storage. When this job has finished successfully, it'll
      launch a separate task that uploads the deposit file to Iron Mountain via SFTP.
    </description>
    <schedule>7 0 * * *</schedule>
    <target>backend</target>
  </cron>

  <cron>
    <url><![CDATA[/_dr/cron/fanout?queue=rde-upload&endpoint=/_dr/task/rdeUpload&forEachRealTld]]></url>
    <name>rdeUpload</name>
    <method>GET</method>
    <description>
      This job is a no-op unless RdeUploadCursor falls behind for some reason.
    </description>
    <schedule>0 */4 * * *</schedule>
    <target>backend</target>
  </cron>

  <cron>
    <url><![CDATA[/_dr/cron/fanout?queue=marksdb&endpoint=/_dr/task/tmchDnl&runInEmpty]]></url>
    <name>tmchDnl</name>
    <method>GET</method>
    <description>
      This job downloads the latest DNL from MarksDB and inserts it into the database.
      (See: TmchDnlAction, ClaimsList)
    </description>
    <schedule>0 */12 * * *</schedule>
    <target>backend</target>
  </cron>

  <cron>
    <url><![CDATA[/_dr/cron/fanout?queue=marksdb&endpoint=/_dr/task/tmchSmdrl&runInEmpty]]></url>
    <name>tmchSmdrl</name>
    <method>GET</method>
    <description>
      This job downloads the latest SMDRL from MarksDB and inserts it into the database.
      (See: TmchSmdrlAction, SignedMarkRevocationList)
    </description>
    <schedule>15 */12 * * *</schedule>
    <target>backend</target>
  </cron>

  <cron>
    <url><![CDATA[/_dr/cron/fanout?queue=marksdb&endpoint=/_dr/task/tmchCrl&runInEmpty]]></url>
    <name>tmchCrl</name>
    <method>GET</method>
    <description>
      This job downloads the latest CRL from MarksDB and inserts it into the database.
      (See: TmchCrlAction)
    </description>
    <schedule>0 */12 * * *</schedule>
    <target>backend</target>
  </cron>

  <cron>
    <url><![CDATA[/_dr/cron/fanout?queue=retryable-cron-tasks&endpoint=/_dr/task/syncGroupMembers&runInEmpty]]></url>
    <name>syncGroupMembers</name>
    <method>GET</method>
    <description>
      Syncs RegistrarContact changes in the past hour to Google Groups.
    </description>
    <schedule>0 */1 * * *</schedule>
    <target>backend</target>
  </cron>

  <cron>
    <url><![CDATA[/_dr/cron/fanout?queue=sheet&endpoint=/_dr/task/syncRegistrarsSheet&runInEmpty]]></url>
    <name>syncRegistrarsSheet</name>
    <method>GET</method>
    <description>
      Synchronize Registrar entities to Google Spreadsheets.
    </description>
    <schedule>0 */1 * * *</schedule>
    <target>backend</target>
  </cron>

  <cron>
    <url><![CDATA[/_dr/task/resaveAllEppResourcesPipeline?fast=true]]></url>
    <name>resaveAllEppResourcesPipeline</name>
    <method>GET</method>
    <description>
      This job resaves all our resources, projected in time to "now".
    </description>
    <schedule>0 9 1 * *</schedule>
    <target>backend</target>
  </cron>

  <cron>
    <url><![CDATA[/_dr/task/expandRecurringBillingEvents?advanceCursor]]></url>
    <name>expandRecurringBillingEvents</name>
    <method>GET</method>
    <description>
      This job runs an action that creates synthetic OneTime billing events from Recurring billing
      events. Events are created for all instances of Recurring billing events that should exist
      between the RECURRING_BILLING cursor's time and the execution time of the action.
    </description>
    <schedule>0 3 * * *</schedule>
    <target>backend</target>
  </cron>

  <cron>
    <url><![CDATA[/_dr/task/deleteExpiredDomains]]></url>
    <name>deleteExpiredDomains</name>
    <method>GET</method>
    <description>
      This job runs an action that deletes domains that are past their
      autorenew end date.
    </description>
    <schedule>7 3 * * *</schedule>
    <target>backend</target>
  </cron>

  <cron>
    <url><![CDATA[/_dr/cron/fanout?queue=retryable-cron-tasks&endpoint=/_dr/task/deleteProberData&runInEmpty]]></url>
    <name>deleteProberData</name>
    <method>GET</method>
    <description>
      This job clears out data from probers and runs once a week.
    </description>
    <schedule>0 14 * * 1</schedule>
    <timezone>UTC</timezone>
    <target>backend</target>
  </cron>

  <!-- TODO: Add borgmon job to check that these files are created and updated successfully. -->
  <cron>
    <url><![CDATA[/_dr/cron/fanout?queue=retryable-cron-tasks&endpoint=/_dr/task/exportReservedTerms&forEachRealTld]]></url>
    <name>exportReservedTerms</name>
    <method>GET</method>
    <description>
      Reserved terms export to Google Drive job for creating once-daily exports.
    </description>
    <schedule>30 5 * * *</schedule>
    <target>backend</target>
  </cron>

  <cron>
    <url><![CDATA[/_dr/cron/fanout?queue=retryable-cron-tasks&endpoint=/_dr/task/exportPremiumTerms&forEachRealTld]]></url>
    <name>exportPremiumTerms</name>
    <method>GET</method>
    <description>
      Premium terms export to Google Drive job for creating once-daily exports.
    </description>
    <schedule>0 5 * * *</schedule>
    <target>backend</target>
  </cron>

  <cron>
    <url><![CDATA[/_dr/cron/readDnsQueue?jitterSeconds=45]]></url>
    <name>readDnsQueue</name>
    <method>GET</method>
    <description>
      Lease all tasks from the dns-pull queue, group by TLD, and invoke PublishDnsUpdates for each
      group.
    </description>
    <schedule>*/1 * * * *</schedule>
    <target>backend</target>
  </cron>
</cronentries>
