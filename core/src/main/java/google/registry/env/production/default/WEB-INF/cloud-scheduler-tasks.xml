<?xml version="1.0" encoding="UTF-8"?>
<entries>
  <task>
    <url>/_dr/task/rdeStaging</url>
    <name>rdeStaging</name>
    <description>
      This job generates a full RDE escrow deposit as a single gigantic XML document
      and streams it to cloud storage. When this job has finished successfully, it'll
      launch a separate task that uploads the deposit file to Iron Mountain via SFTP.
    </description>
    <!--
      This only needs to run once per day, but we launch additional jobs in case the
      cursor is lagging behind, so it'll catch up to the current date as quickly as
      possible. The only job that'll run under normal circumstances is the one that's
      close to midnight, since if the cursor is up-to-date, the task is a no-op.
      We want it to be close to midnight because that reduces the chance that the
      point-in-time code won't have to go to the extra trouble of fetching old
      versions of objects from the database. However, we don't want it to run too
      close to midnight, because there's always a chance that a change which was
      timestamped before midnight hasn't fully been committed to the database. So
      we add a 4+ minute grace period to ensure the transactions cool down, since
      our queries are not transactional.
    -->
    <schedule>7 */8 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=rde-upload&endpoint=/_dr/task/rdeUpload&forEachRealTld]]></url>
    <name>rdeUpload</name>
    <description>
      This job is a no-op unless RdeUploadCursor falls behind for some reason.
    </description>
    <schedule>0 */4 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=rde-report&endpoint=/_dr/task/rdeReport&forEachRealTld]]></url>
    <name>rdeReport</name>
    <description>
      This job is a no-op unless RdeReportCursor falls behind for some reason.
    </description>
    <schedule>0 */4 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=marksdb&endpoint=/_dr/task/tmchDnl&runInEmpty]]></url>
    <name>tmchDnl</name>
    <description>
      This job downloads the latest DNL from MarksDB and inserts it into the database.
      (See: TmchDnlAction, ClaimsList)
    </description>
    <schedule>0 0,12 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=marksdb&endpoint=/_dr/task/tmchSmdrl&runInEmpty]]></url>
    <name>tmchSmdrl</name>
    <description>
      This job downloads the latest SMDRL from MarksDB and inserts it into the database.
      (See: TmchSmdrlAction, SignedMarkRevocationList)
    </description>
    <schedule>15 */12 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=marksdb&endpoint=/_dr/task/tmchCrl&runInEmpty]]></url>
    <name>tmchCrl</name>
    <description>
      This job downloads the latest CRL from MarksDB and inserts it into the database.
      (See: TmchCrlAction)
    </description>
    <schedule>0 */12 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=retryable-cron-tasks&endpoint=/_dr/task/syncGroupMembers&runInEmpty]]></url>
    <name>syncGroupMembers</name>
    <description>
      Syncs RegistrarContact changes in the past hour to Google Groups.
    </description>
    <schedule>0 */1 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=sheet&endpoint=/_dr/task/syncRegistrarsSheet&runInEmpty]]></url>
    <name>syncRegistrarsSheet</name>
    <description>
      Synchronize Registrar entities to Google Spreadsheets.
    </description>
    <schedule>0 */1 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/task/resaveAllEppResourcesPipeline?fast=true]]></url>
    <name>resaveAllEppResourcesPipeline</name>
    <description>
      This job resaves all our resources, projected in time to "now".
    </description>
    <!--
    Deviation from cron tasks schedule: 1st monday of month 09:00 is replaced
    with 1st of the month 09:00
    -->
    <schedule>0 9 1 * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/task/updateRegistrarRdapBaseUrls]]></url>
    <name>updateRegistrarRdapBaseUrls</name>
    <description>
      This job reloads all registrar RDAP base URLs from ICANN.
    </description>
    <schedule>34 2 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=retryable-cron-tasks&endpoint=/_dr/task/exportDomainLists&runInEmpty]]></url>
    <name>exportDomainLists</name>
    <description>
      This job exports lists of all active domain names to Google Drive and Google Cloud Storage.
    </description>
    <schedule>0 */12 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/task/expandBillingRecurrences?advanceCursor]]></url>
    <name>expandBillingRecurrences</name>
    <description>
      This job runs an action that creates synthetic one-time billing events
      from billing recurrences. Events are created for all recurrences that
      should exist between the RECURRING_BILLING cursor's time and the execution
      time of the action.
    </description>
    <schedule>0 3 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/task/deleteExpiredDomains]]></url>
    <name>deleteExpiredDomains</name>
    <description>
      This job runs an action that deletes domains that are past their
      autorenew end date.
    </description>
    <schedule>7 3 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/task/sendExpiringCertificateNotificationEmail]]></url>
    <name>sendExpiringCertificateNotificationEmail</name>
    <description>
      This job runs an action that sends emails to partners if their certificates are expiring soon.
    </description>
    <schedule>30 4 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=nordn&endpoint=/_dr/task/nordnUpload&forEachRealTld&lordnPhase=sunrise]]></url>
    <name>nordnUploadSunrise</name>
    <description>
      This job uploads LORDN Sunrise CSV files for each TLD to MarksDB. It should be
      run at most every three hours, or at absolute minimum every 26 hours.
    </description>
    <!-- This may be set anywhere between "every 3 hours" and "every 25 hours". -->
    <schedule>0 */12 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=nordn&endpoint=/_dr/task/nordnUpload&forEachRealTld&lordnPhase=claims]]></url>
    <name>nordnUploadClaims</name>
    <description>
      This job uploads LORDN Claims CSV files for each TLD to MarksDB. It should be
      run at most every three hours, or at absolute minimum every 26 hours.
    </description>
    <!-- This may be set anywhere between "every 3 hours" and "every 25 hours". -->
    <schedule>0 */12 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=retryable-cron-tasks&endpoint=/_dr/task/deleteProberData&runInEmpty]]></url>
    <name>deleteProberData</name>
    <description>
      This job clears out data from probers and runs once a week.
    </description>
    <schedule>0 14 * * 1</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=retryable-cron-tasks&endpoint=/_dr/task/exportReservedTerms&forEachRealTld]]></url>
    <name>exportReservedTerms</name>
    <description>
      Reserved terms export to Google Drive job for creating once-daily exports.
    </description>
    <schedule>30 5 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=retryable-cron-tasks&endpoint=/_dr/task/exportPremiumTerms&forEachRealTld]]></url>
    <name>exportPremiumTerms</name>
    <description>
      Exports premium price lists to the Google Drive folders for each TLD once per day.
    </description>
    <schedule>0 5 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/readDnsQueue?jitterSeconds=45]]></url>
    <name>readDnsQueue</name>
    <description>
      Lease all tasks from the dns-pull queue, group by TLD, and invoke PublishDnsUpdates for each
      group.
    </description>
    <schedule>*/1 * * * *</schedule>
  </task>

  <task>
    <url>
      <![CDATA[/_dr/cron/fanout?queue=dns-refresh&forEachRealTld&forEachTestTld&endpoint=/_dr/task/readDnsRefreshRequests&dnsJitterSeconds=45]]></url>
    <name>readDnsRefreshRequests</name>
    <description>
      Enqueue a ReadDnsRefreshRequestAction for each TLD.
    </description>
    <schedule>*/1 * * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=retryable-cron-tasks&endpoint=/_dr/task/icannReportingStaging&runInEmpty]]></url>
    <name>icannReportingStaging</name>
    <description>
      Create ICANN activity and transaction reports for last month, storing them in
      gs://[PROJECT-ID]-reporting/icann/monthly/yyyy-MM
      Upon success, enqueues the icannReportingUpload task to POST these files to ICANN.
    </description>
    <schedule>0 9 2 * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=retryable-cron-tasks&endpoint=/_dr/task/icannReportingUpload&runInEmpty]]></url>
    <name>icannReportingUpload</name>
    <description>
      Checks if the monthly ICANN reports have been successfully uploaded. If they have not, attempts to upload them again.
      Most of the time, this job should not do anything since the uploads are triggered when the reports are staged.
      However, in the event that an upload failed for any reason (e.g. ICANN server is down, IP allow list issues),
      this cron job will continue to retry uploads daily until they succeed.
    </description>
    <schedule>0 15 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=retryable-cron-tasks&endpoint=/_dr/task/generateInvoices?shouldPublish=true&runInEmpty]]></url>
    <name>generateInvoices</name>
    <description>
      Starts the beam/billing/InvoicingPipeline Dataflow template, which creates the overall invoice and
      detail report CSVs for last month, storing them in gs://[PROJECT-ID]-billing/invoices/yyyy-MM.
      Upon success, sends an e-mail copy of the invoice to billing personnel, and copies detail
      reports to the associated registrars' drive folders.
      See GenerateInvoicesAction for more details.
    </description>
    <!--WARNING: This must occur AFTER expandBillingRecurrences and AFTER exportSnapshot, as
    it uses Bigquery as the source of truth for billable events. ExportSnapshot usually takes
    about 2 hours to complete, so we give 11 hours to be safe. Normally, we give 24+ hours (see
    icannReportingStaging), but the invoicing team prefers receiving the e-mail on the first of
    each month. -->
    <schedule>0 19 1 * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/cron/fanout?queue=retryable-cron-tasks&endpoint=/_dr/task/generateSpec11&runInEmpty]]></url>
    <name>generateSpec11</name>
    <description>
      Starts the beam/spec11/Spec11Pipeline Dataflow template, which creates today's Spec11
      report. This report is stored in gs://[PROJECT-ID]-reporting/icann/spec11/yyyy-MM/.
      This job will only send email notifications on the second of every month.
      See GenerateSpec11ReportAction for more details.
    </description>
    <schedule>0 15 * * *</schedule>
  </task>

  <task>
    <url><![CDATA[/_dr/task/wipeOutContactHistoryPii]]></url>
    <name>wipeOutContactHistoryPii</name>
    <description>
      This job runs weekly to wipe out PII fields of ContactHistory entities
      that have been in the database for a certain period of time.
    </description>
    <schedule>0 15 * * 1</schedule>
  </task>
</entries>
